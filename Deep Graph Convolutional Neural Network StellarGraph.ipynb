{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b19952a",
   "metadata": {},
   "source": [
    "# Graph Classification with the PROTEINS Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1452f06f",
   "metadata": {},
   "source": [
    "Graph classification is the task of predicting an attribute or label of an entire graph. This is in contrast with node classification, for example, in which we are only interested in predicting the labels of the nodes in the graph. \n",
    "\n",
    "There are many possible applications of graph classification: determining the type of network a group of individuals forms (friendship group, work colleagues, family etc.), the classification of newly discovered molecules, determining the type of vehicle making a journey on a road network, and so on.\n",
    "\n",
    "In this notebook we are going to employ graph classification to predict whether a protein is an enzyme or non-enzyme. Proteins can be represented as graphs, with the amino acids in the protein serving as the graph nodes, and the bonds between these amino acids as the graph edges. The dataset we are going to use is the PROTEINS dataset, which is a benchmark dataset for graph classification tasks. \n",
    "\n",
    "To perform graph classification we are going to utilise the StellarGraph Python library to construct and train a Deep Graph Convolutional Neural Network (DGCNN). StellarGraph offers a wide variety of state-of-the-art algorithms for graph Machine Learning, and is very intuitive to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c13c216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import stellargraph as sg\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "from stellargraph import datasets\n",
    "from stellargraph.mapper import PaddedGraphGenerator\n",
    "from stellargraph.layer import DeepGraphCNN\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPool1D, Dropout, Flatten\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2ca379",
   "metadata": {},
   "source": [
    "We begin by loading the PROTEINS dataset which is included in StellarGraph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "833cabfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each graph represents a protein and graph labels represent whether they are are enzymes or non-enzymes. The dataset includes 1113 graphs with 39 nodes and 73 edges on average for each graph. Graph nodes have 4 attributes (including a one-hot encoding of their label), and each graph is labelled as belonging to 1 of 2 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.PROTEINS()\n",
    "print(dataset.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1fb6b5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs, labels = dataset.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d28801c",
   "metadata": {},
   "source": [
    "Let's have a look at one of the protein graph objects in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cfb20174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 10, Edges: 34\n",
      "\n",
      " Node types:\n",
      "  default: [10]\n",
      "    Features: float32 vector, length 4\n",
      "    Edge types: default-default->default\n",
      "\n",
      " Edge types:\n",
      "    default-default->default: [34]\n",
      "        Weights: all 1 (default)\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "print(graphs[2].info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23cbd85",
   "metadata": {},
   "source": [
    "This graph is a multigraph (two nodes may be connected by multiple edges) and has undirected edges. It has 10 nodes and 34 edges. The nodes have four features, as expected, and the edges have none. All edges are weighted equally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0bd2bd",
   "metadata": {},
   "source": [
    "Let's have a look at this graph's nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "389d22f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([70, 71, 72, 73, 74, 75, 76, 77, 78, 79], dtype='int64')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs[2].nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1539e41",
   "metadata": {},
   "source": [
    "Let's look at the edges that run between these nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88876060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(71, 70),\n",
       " (72, 70),\n",
       " (79, 70),\n",
       " (70, 71),\n",
       " (72, 71),\n",
       " (79, 71),\n",
       " (70, 72),\n",
       " (71, 72),\n",
       " (73, 72),\n",
       " (79, 72),\n",
       " (72, 73),\n",
       " (74, 73),\n",
       " (75, 73),\n",
       " (73, 74),\n",
       " (75, 74),\n",
       " (76, 74),\n",
       " (73, 75),\n",
       " (74, 75),\n",
       " (76, 75),\n",
       " (77, 75),\n",
       " (78, 75),\n",
       " (74, 76),\n",
       " (75, 76),\n",
       " (77, 76),\n",
       " (78, 76),\n",
       " (75, 77),\n",
       " (76, 77),\n",
       " (78, 77),\n",
       " (75, 78),\n",
       " (76, 78),\n",
       " (77, 78),\n",
       " (70, 79),\n",
       " (71, 79),\n",
       " (72, 79)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs[2].edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7a7662",
   "metadata": {},
   "source": [
    "We can get the degree of each graph node. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5232ba9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {70: 6,\n",
       "             71: 6,\n",
       "             72: 8,\n",
       "             73: 6,\n",
       "             74: 6,\n",
       "             75: 10,\n",
       "             76: 8,\n",
       "             77: 6,\n",
       "             78: 6,\n",
       "             79: 6})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs[2].node_degrees()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db967a48",
   "metadata": {},
   "source": [
    "We can get the adjacent neighbours to a node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43dded50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[72, 75, 74, 72, 75, 74]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs[2].neighbors(73)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b862ad98",
   "metadata": {},
   "source": [
    "Now let's take a look at the labels of all the graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0256fdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "5       1\n",
      "       ..\n",
      "1109    2\n",
      "1110    2\n",
      "1111    2\n",
      "1112    2\n",
      "1113    2\n",
      "Name: label, Length: 1113, dtype: category\n",
      "Categories (2, object): ['1', '2']\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18814550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "1    663\n",
       "2    450"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce481bc",
   "metadata": {},
   "source": [
    "As we can see, there are more samples of label 1 than label 2 (59.5% to 40.5%).\n",
    "\n",
    "We are going to simplify by changing the labels to zeros and ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9645035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "...  ..\n",
      "1109  1\n",
      "1110  1\n",
      "1111  1\n",
      "1112  1\n",
      "1113  1\n",
      "\n",
      "[1113 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "labels = pd.get_dummies(labels, drop_first=True)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e1ba6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "2     \n",
       "0  663\n",
       "1  450"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78683ca1",
   "metadata": {},
   "source": [
    "It is always a good idea to shuffle the data before using it in a Machine Learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06d4a2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs, labels = shuffle(graphs, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee061805",
   "metadata": {},
   "source": [
    "Now we are going to define some methods that will separate our graphs and labels into training, validation and testing sets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f30eddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessing:\n",
    "    \n",
    "    def __init__(self, graphs, labels):\n",
    "        \n",
    "        self.graphs = graphs\n",
    "        self.labels = labels\n",
    "        \n",
    "\n",
    "    def training_testing_sets(self, test_size):\n",
    "        \n",
    "        # splits the data into training and testing sets\n",
    "        train_graphs, test_graphs, train_labels, test_labels = train_test_split(self.graphs, self.labels, \n",
    "                                                                                test_size = test_size, random_state = 3)\n",
    "        return train_graphs, test_graphs, train_labels, test_labels\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def train_valid_sets(train_graphs, train_labels, validation_size):\n",
    "        \n",
    "        # create a validation set from the training set\n",
    "        training_size = int((1-validation_size)*1000)\n",
    "        validation_size = int(1000*validation_size)\n",
    "        # for later use in generators we only require the split indices and not the splits themselves\n",
    "        train_index = [i for i in range(training_size)]\n",
    "        valid_index = [i for i in range(training_size, training_size+validation_size+1)]\n",
    "        # get the corresponding labels\n",
    "        train_labels1 = train_labels[:training_size]\n",
    "        valid_labels = train_labels[training_size:]\n",
    "        return train_index, valid_index, train_labels1, valid_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09844ae",
   "metadata": {},
   "source": [
    "Let's perform the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0579897d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessing = DataPreprocessing(graphs, labels)\n",
    "train_graphs, test_graphs, train_labels_0, test_labels = data_preprocessing.training_testing_sets(0.1)\n",
    "train_index, valid_index, train_labels, valid_labels = data_preprocessing.train_valid_sets(train_graphs, train_labels_0, \n",
    "                                                                                     validation_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4be362e",
   "metadata": {},
   "source": [
    "The DGCNN model we are going to implement for graph classification is adapted from the paper \"An End-to-End Deep Learning Architecture for Graph Classification\" by Zhang, M., et al, 2018. The DGCNN model arised from the desire of the authors to improve the performance of spatial graph convolutional neural networks for graph classification. Previous attempts were disappointing; one reason was that much of a graph's rich node information was summend up into graph-level features. Their new model attempted to rectify this by retaining more of a graph's node information and learning from its topology. The first layers of the DGCNN are the spatial graph convolution layers, defined by\n",
    "\n",
    "$$Z = \\sigma\\left(\\bar{D^{-1}}\\bar{A}XW\\right)\\tag*{(1)}$$\n",
    "\n",
    "where $\\sigma$ is a non-linear activation function, $\\bar{A} = A + I$ is the adjacency matrix of the graph with added self-loops (self-loops appear as the diagonal elements in an adjacency matrix), $\\bar{D}$ is the degree matrix corresponding to $\\bar{A}$, $X$ is the graph's node information matrix (each row consists of a node's feature vector), and $W$ is a weights matrix. Let's use an example with some $3\\times3$ matrices to see how the convolution works: \n",
    "\n",
    "$$\\begin{align}\\bar{A}XW &= \\begin{pmatrix}\n",
    "1 & a_{12} & a_{13}\\\\\n",
    "a_{21} & 1 & a_{23}\\\\\n",
    "a_{31} & a_{32} & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "x_{11} & x_{12} & x_{13}\\\\\n",
    "x_{21} & x_{22} & x_{23}\\\\\n",
    "x_{31} & x_{32} & x_{33}\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "w_{11} & w_{12} & w_{13}\\\\\n",
    "w_{21} & w_{22} & w_{23}\\\\\n",
    "w_{31} & w_{32} & w_{33}\n",
    "\\end{pmatrix}\\\\\n",
    "&= \\begin{pmatrix}\n",
    "1 & a_{12} & a_{13}\\\\\n",
    "a_{21} & 1 & a_{23}\\\\\n",
    "a_{31} & a_{32} & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "x_{11}w_{11}+x_{12}w_{21}+x_{13}w_{31} & x_{11}w_{12}+x_{12}w_{22}+x_{13}w_{32} & x_{11}w_{13}+x_{12}w_{23}+x_{13}w_{33}\\\\\n",
    "x_{21}w_{11}+x_{22}w_{21}+x_{23}w_{31} & x_{21}w_{12}+x_{22}w_{22}+x_{23}w_{32} & x_{21}w_{13}+x_{22}w_{23}+x_{23}w_{33}\\\\\n",
    "x_{31}w_{11}+x_{32}w_{21}+x_{33}w_{31} & x_{31}w_{12}+x_{32}w_{22}+x_{33}w_{32} & x_{31}w_{13}+x_{32}w_{23}+x_{33}w_{33}\n",
    "\\end{pmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "If we look at, say $(\\bar{A}XW)_{11}$, the first element of the first row of $\\bar{A}XW$, we will have the matrix element\n",
    "\n",
    "$$\n",
    "x_{11}w_{11}+x_{12}w_{21}+x_{13}w_{31} + a_{12}(x_{21}w_{11}+x_{22}w_{21}+x_{23}w_{31}) + a_{13}(x_{31}w_{11}+x_{32}w_{21}+x_{33}w_{31})\n",
    "$$\n",
    "\n",
    "This is just \n",
    "$$(XW)_{11}+a_{12}(XW)_{21}+a_{13}(XW)_{31}\\tag*{(2)}$$\n",
    "\n",
    "Therefore, $XW$ represents a linear transformation of the node information matrix, and $\\bar{A}XW$ propagates a node's information to its neighbours, and not just itself. Information is only propagated to a node's neighbours since in the adjacency matrix $\\bar{A}$, elements are zero between nodes that are not adjacent.\n",
    "\n",
    "Next comes the multiplication by $\\bar{D^{-1}}$ which normalises each row of $\\bar{A}XW$ to keep a fixed feature scale after convolution. We can see how this works with a simple example using $2\\times2$ matrices:\n",
    "\n",
    "Let's say that we have $\\bar{A} = \\begin{pmatrix}\n",
    "1 & a_{12}\\\\\n",
    "a_{21} & 1\n",
    "\\end{pmatrix}$\n",
    "\n",
    "This would mean that \n",
    "\n",
    "$$\\bar{D} = \\begin{pmatrix}\n",
    "1+a_{12} & 0\\\\\n",
    "0 & 1+a_{21}\n",
    "\\end{pmatrix}$$ and $$\\bar{D^{-1}} = \\frac{1}{(1+a_{21})(1+a_{12})}\\begin{pmatrix}\n",
    "1+a_{21} & 0\\\\\n",
    "0 & 1+a_{12}\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "Multiplying $\\bar{D^{-1}}$ and $\\bar{A}$ together we get\n",
    "\n",
    "$$\\begin{align}\\bar{D^{-1}}\\bar{A} &= \\frac{1}{(1+a_{21})(1+a_{12})}\\begin{pmatrix}\n",
    "1+a_{21} & 0\\\\\n",
    "0 & 1+a_{12}\n",
    "\\end{pmatrix}\\begin{pmatrix}\n",
    "1 & a_{12}\\\\\n",
    "a_{21} & 1\n",
    "\\end{pmatrix}\\\\\n",
    "&= \\begin{pmatrix}\n",
    "\\frac{1}{1+a_{12}} & \\frac{a_{12}}{1+a_{12}}\\\\\n",
    "\\frac{a_{21}}{1+a_{21}} & \\frac{1}{1+a_{21}}\n",
    "\\end{pmatrix}\\end{align}$$\n",
    "\n",
    "Adding the first row's elements we get \n",
    "$$\\frac{1}{1+a_{12}} + \\frac{a_{12}}{1+a_{12}} = \\frac{1+a_{12}}{1+a_{12}} = 1$$\n",
    "\n",
    "Adding the second row's elements we get\n",
    "$$\\frac{a_{21}}{1+a_{21}} + \\frac{1}{1+a_{21}} = \\frac{1+a_{21}}{1+a_{21}} = 1$$\n",
    "\n",
    "i.e., the rows are normalised to unity. \n",
    "\n",
    "A single graph convolution layer aggregates node information in local neighbourhoods to extract local substructure information. To extract multi-scale substructure features we must stack multiple graph convolution layers according to \n",
    "\n",
    "$$Z^{n+1} = \\sigma\\left(\\bar{D^{-1}}\\bar{A}Z^nW^n\\right)$$\n",
    "\n",
    "where $Z^n$ is the output of the nth graph convolution layer ($Z^0 = X$), and $W^n$ is the weights matrix for the nth layer.\n",
    "\n",
    "After the convolution layers, all the outputs, the $Z^i$, are concatenated together horizontally to form a new matrix $Z^{1:p}$, where $p$ is the number of convolution layers. Each row of $Z^{1:p}$ will consist of the output computed for the same node in each of the convolution layers. For example, if we have three convolution layers and the rows for, say, node A in each layer are $(z^1_{A})$, $(z^2_{A})$, and $(z^3_{A})$ respectively, then the row for node A in $Z^{1:3}$ will be $(z^1_{A}\\quad z^2_{A}\\quad z^3_{A})$. The rows of $Z^{1:p}$ are called the feature descriptors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1297b200",
   "metadata": {},
   "source": [
    "After the graph convolution layers comes the sort-pooling layer. The main function of this layer is to sort the node feature descriptors in a consistent manner before passing them on to the conventional convolutional and fully-connected layers. The sort-pooling layer is able to do this since the output of the final graph convolution layer is the same as that of the Weisfeiler-Lehman (WL) algorithm. \n",
    "\n",
    "The WL algorithm is typically employed to determine if two graphs are isomorphic. It's first step is to give all the graph nodes the same label, or colour. A node is then assigned a tuple which is comprised of two parts: the node's colour, and a multiset (a set which allows multiple instances of the same element) of the colours of the node's one-hop neighbours. New colours are assigned again, with any nodes sharing identical tuples taking the same colour. This process is repeated again and again until the colours converge or some maximum iteration is reached. For a better description see [here](https://davidbieber.com/post/2019-05-10-weisfeiler-lehman-isomorphism-test/). Since the algorithm utilises only the structure of the graph, nodes that finish with the same colour will have the same structural role in the graph.\n",
    "\n",
    "We can see from equations (1) and (2) that the i-th row of $Z$ can be expressed as\n",
    "$$Z_{i} = \\sigma\\Biggl\\{\\bar{D^{-1}}_{ii}\\left[(XW)_{i} + \\sum_{j} (XW)_{j}\\right]\\Biggr\\}$$\n",
    "where the $j$ represent the nodes adjacent to node $i$.\n",
    "\n",
    "The portion within the curly brackets is analogous to the tuple label in the WL algorithm, since it is aggregating the feature information of node i and its neighbours (In the WL algorithm, node i's colour is aggregated with those of its neighbours). The non-linear function $\\sigma$ then effectively maps this aggregated feature information to a new colour.\n",
    "\n",
    "The input to the sort-pooling layer, $Z^{1:p}$, is first sorted according to $Z^{p}$, the final output layer, since the colours in this layer can be considered the most refined. Nodes (rows) are sorted in descending order according to the final column of $Z^{p}$. If there exists a tie between two or more nodes, the second to last columns are compared, and so on. If the ties continue, the columns are then compared in $Z^{p-1}$, $Z^{p-2}$, and so on. In this way, graph nodes are consistently ordered, permitting the training of traditional neural networks on the representations.\n",
    "\n",
    "Another caracteristic of the sort-pooling layer is that it standardises, to an integer $k$, the number of rows in the output $Z^{p}$. Rows can be added or deleted, depending on whether the output has less or more rows than $k$, respectively. This enables the model to be trained on graphs consisting of varying numbers of nodes. Furthermore, the sort-pooling layer is able to pass loss function gradients back to the previous layers by remembering the sorted order of its input. Therefore, the parameters of these layers can be trained and backpropagation undertaken. \n",
    "\n",
    "The final output from the sort-pooling layer is reshaped into a $k\\sum_{1}^{p}c_n \\times 1$ vector, where $c_n$ is the number of feature channels (columns) of layer $n$. For example, if we have three layers and $c_{1} = 6$, $c_{1} = 5$, $c_{1} = 4$, and we choose $k = 10$, the reshaped output will be a $(150 \\times 1)$ vector. The first 1D-convolutional layer is chosen to have a filter size and stride length of $\\sum_{1}^{p}c_n$. The consequence of this is that filters are applied sequentially on vertices' feature descriptors. Returning to our example, a filter is first applied to the 15 feature descriptors (six in the first layer, five in the second, four in the thrid) of node one (for lack of a better naming convention), then to the 15 feature descriptors of node two, and so on, until the filter has been applied to all $k=10$ nodes. A max-pooling layer and another 1D-convolutional layer are then employed to learn local patterns on the node sequence. These are followed by several fully-connected layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2527433",
   "metadata": {},
   "source": [
    "Now we are going to create our DGCNN model using StellarGraph and Keras. Initially, we require generator methods that will pass the data into the model in batches. The first layers in the DGCNN are the graph convolutional layers. Following these are a sort-pooling layer and a standard convolutional layer. Next comes a max-pooling layer, followed by another convolutional layer. The output is flattened and passed through three fully-connected layers, with the last being the output layer. The model is then layered together and configured; we choose the Adam optimisation algorithm and an appropriate cost function. There are also methods that will employ the DGCNN to make predictions on the testing set and evaluate the model's performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88a17750",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DGCNN:\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def create_generator(graphs):\n",
    "        \n",
    "        # PaddedGraphGenerator supplies the features arrays and the adjacency matrices to a mini-batch Keras\n",
    "        # graph classification model.\n",
    "        generator = PaddedGraphGenerator(graphs=graphs)\n",
    "        return generator\n",
    "\n",
    "\n",
    "    def get_training_generators(self, train_graphs, train_index, train_labels, valid_index, valid_labels, batch_size):\n",
    "        \n",
    "        # create generator of training data\n",
    "        self.training_generator = self.create_generator(train_graphs)\n",
    "        # flow reates a generator/sequence object for training, evaluation, or prediction\n",
    "        # with the supplied graph indexes and targets.\n",
    "        # generate generator flow objects for training and validation data.\n",
    "        self.train_gen = self.training_generator.flow(train_index, targets = train_labels, \n",
    "                                                              batch_size = batch_size)\n",
    "        self.valid_gen = self.training_generator.flow(valid_index, targets = valid_labels, \n",
    "                                                              batch_size = batch_size)\n",
    "\n",
    "\n",
    "\n",
    "    def get_testing_generator(self, test_graphs, test_labels):\n",
    "        \n",
    "        # create generator of testing data\n",
    "        testing_generator = self.create_generator(test_graphs)\n",
    "        # create generator flow object\n",
    "        self.test_gen = testing_generator.flow(test_graphs, targets = test_labels, batch_size =1, \n",
    "                                               symmetric_normalization = False)\n",
    "        \n",
    "\n",
    "    def create_DGCNN(self, layer_sizes, activations, k, num_kernels, kernel_sizes, strides, \n",
    "              pool_size, num_neurons, fc_activations):\n",
    "        \n",
    "        # add a stack of graph convolution layers with a sort-pooling layer\n",
    "        dgcnn = DeepGraphCNN(layer_sizes = layer_sizes, activations = activations, k = k, bias = False, \n",
    "                             generator = self.training_generator)\n",
    "        # access the input and output tensors of the graph convolution layers\n",
    "        x_inp, x_out = dgcnn.in_out_tensors()\n",
    "        # first conventional convolutional layer\n",
    "        output1 = Conv1D(filters = num_kernels[0], kernel_size = kernel_sizes[0], strides = strides[0])(x_out)\n",
    "        # max-pooling layer\n",
    "        output2 = MaxPool1D(pool_size = pool_size)(output1)\n",
    "        # second conventional convolutional layer\n",
    "        output3 = Conv1D(filters = num_kernels[1], kernel_size = kernel_sizes[1], strides = strides[1])(output2)\n",
    "        # flatten output for dense layers\n",
    "        output4 = Flatten()(output3)\n",
    "        # first dense layer\n",
    "        output5 = Dense(units = num_neurons[0], activation = fc_activations[0])(output4)\n",
    "        # second dense layer\n",
    "        output7 = Dense(units = num_neurons[1], activation = fc_activations[1])(output4)\n",
    "        # output layer\n",
    "        predictions = Dense(units = 1, activation = fc_activations[2])(output7)\n",
    "        # group all layers into model object\n",
    "        self.model = Model(inputs = x_inp, outputs = predictions)\n",
    "\n",
    "\n",
    "\n",
    "    def configure_train_DGCNN(self, learning_rate, loss_function, epochs):\n",
    "        \n",
    "        # configure model\n",
    "        self.model.compile(optimizer = Adam(learning_rate = learning_rate), loss = loss_function, metrics = ['acc'])\n",
    "        # train model with training and validation sets\n",
    "        self.history = self.model.fit(self.train_gen, epochs = epochs, verbose = 1, validation_data = self.valid_gen,\n",
    "                                 shuffle = False)\n",
    "        \n",
    "\n",
    " \n",
    "    @staticmethod        \n",
    "    def get_prediction_assessment(row):\n",
    "        \n",
    "        # this function indicates whether a prediction is a true-positive, true-negative, false-positive,\n",
    "        # or false-negative\n",
    "    \n",
    "        prediction = row['prediction']\n",
    "        label = row['label']\n",
    "        if prediction > 0.5 and label == 1:\n",
    "            return 'TP'\n",
    "        elif prediction < 0.5 and label == 1:\n",
    "            return 'FN'\n",
    "        elif prediction > 0.5 and label == 0:\n",
    "            return 'FP'\n",
    "        else:\n",
    "            return 'TN'\n",
    "        \n",
    "    \n",
    "    def get_test_results(self):\n",
    "           \n",
    "        # get predictions on the test set\n",
    "        predictions = self.model.predict(self.test_gen)\n",
    "        # convert to list\n",
    "        predictions2 = [i[0] for i in predictions]\n",
    "        # create dataframe of the results\n",
    "        results_dict = {'prediction': predictions2, 'label': test_labels['2'].tolist()}\n",
    "        self.results_df = pd.DataFrame(data=results_dict)\n",
    "        self.results_df['assessment'] = self.results_df.apply(lambda row: self.get_prediction_assessment(row), axis = 1)\n",
    "        \n",
    "   \n",
    "    def evaluate_results(self):\n",
    "        \n",
    "        # get class labels for the model's predicted probabilities \n",
    "        self.predicted_classes = np.where(self.results_df['prediction'] > 0.5, 1, 0)\n",
    "        # generate confusion matrix and classification report\n",
    "        self.confusion_matrix = confusion_matrix(self.results_df['label'], self.predicted_classes)\n",
    "        self.classification_report = classification_report(self.results_df['label'], self.predicted_classes)\n",
    "        \n",
    "    \n",
    "    def training_history(self):\n",
    "        \n",
    "        # produce plots of loss and metric history\n",
    "        sg.utils.plot_history(self.history)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022d53cc",
   "metadata": {},
   "source": [
    "The argument layer_sizes of the create_DGCNN method refers to the number of columns in the output of the graph convolution layers, i.e., the number of columns in the $Z^p$. We will use the same number of graph convolution layers, with the same number of output columns as Zhang et al, i.e., four convolution layers with the first three having 32 output columns and the last having one, with this single column being the only one utilised for sorting the nodes, out of convenience. The numbers of kernels used in the 1D-convolutional layers follows those used by Zhang et al, as do the activation functions used in the graph convolution and fully-connected layers. Unlike Zhang et al, we do not use a dropout layer, since performance on the test set was improved wihtout one. Performance on the test set deteriorated for larger learning rates, so this was kept very small. Since our problem is a binary classification task, the cross-entropy cost function was employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c8a039e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 [==============================] - 8s 115ms/step - loss: 0.6387 - acc: 0.6144 - val_loss: 0.5763 - val_acc: 0.6931\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 4s 100ms/step - loss: 0.6156 - acc: 0.6767 - val_loss: 0.5704 - val_acc: 0.7723\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 3s 81ms/step - loss: 0.6040 - acc: 0.7011 - val_loss: 0.5682 - val_acc: 0.7624\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.5966 - acc: 0.7189 - val_loss: 0.5647 - val_acc: 0.7723\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.5914 - acc: 0.7178 - val_loss: 0.5607 - val_acc: 0.7723\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.5873 - acc: 0.7178 - val_loss: 0.5558 - val_acc: 0.7723\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.5840 - acc: 0.7178 - val_loss: 0.5518 - val_acc: 0.7723\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.5817 - acc: 0.7156 - val_loss: 0.5477 - val_acc: 0.7723\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.5793 - acc: 0.7167 - val_loss: 0.5445 - val_acc: 0.7723\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.5770 - acc: 0.7189 - val_loss: 0.5415 - val_acc: 0.7723\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.5749 - acc: 0.7200 - val_loss: 0.5391 - val_acc: 0.7723\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.5728 - acc: 0.7222 - val_loss: 0.5365 - val_acc: 0.7723\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.5713 - acc: 0.7256 - val_loss: 0.5332 - val_acc: 0.7723\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.5693 - acc: 0.7267 - val_loss: 0.5332 - val_acc: 0.7723\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.5673 - acc: 0.7233 - val_loss: 0.5313 - val_acc: 0.7723\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.5653 - acc: 0.7233 - val_loss: 0.5283 - val_acc: 0.7723\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.5634 - acc: 0.7211 - val_loss: 0.5253 - val_acc: 0.7723\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.5613 - acc: 0.7200 - val_loss: 0.5231 - val_acc: 0.7723\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.5594 - acc: 0.7200 - val_loss: 0.5212 - val_acc: 0.7723\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.5592 - acc: 0.7233 - val_loss: 0.5201 - val_acc: 0.7624\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.5571 - acc: 0.7222 - val_loss: 0.5172 - val_acc: 0.7624\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.5565 - acc: 0.7244 - val_loss: 0.5171 - val_acc: 0.7624\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 3s 97ms/step - loss: 0.5553 - acc: 0.7278 - val_loss: 0.5172 - val_acc: 0.7624\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 3s 96ms/step - loss: 0.5537 - acc: 0.7322 - val_loss: 0.5174 - val_acc: 0.7624\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.5527 - acc: 0.7289 - val_loss: 0.5158 - val_acc: 0.7624\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.5516 - acc: 0.7300 - val_loss: 0.5154 - val_acc: 0.7624\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.5515 - acc: 0.7300 - val_loss: 0.5158 - val_acc: 0.7624\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.5505 - acc: 0.7333 - val_loss: 0.5145 - val_acc: 0.7426\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.5492 - acc: 0.7333 - val_loss: 0.5142 - val_acc: 0.7426\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.5483 - acc: 0.7356 - val_loss: 0.5146 - val_acc: 0.7525\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.5476 - acc: 0.7378 - val_loss: 0.5145 - val_acc: 0.7426\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.5470 - acc: 0.7367 - val_loss: 0.5140 - val_acc: 0.7426\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.5455 - acc: 0.7378 - val_loss: 0.5137 - val_acc: 0.7525\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 4s 100ms/step - loss: 0.5445 - acc: 0.7400 - val_loss: 0.5131 - val_acc: 0.7525\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.5441 - acc: 0.7433 - val_loss: 0.5119 - val_acc: 0.7525\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.5428 - acc: 0.7411 - val_loss: 0.5115 - val_acc: 0.7525\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.5420 - acc: 0.7389 - val_loss: 0.5104 - val_acc: 0.7624\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.5410 - acc: 0.7411 - val_loss: 0.5117 - val_acc: 0.7624\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.5398 - acc: 0.7411 - val_loss: 0.5131 - val_acc: 0.7624\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.5387 - acc: 0.7444 - val_loss: 0.5125 - val_acc: 0.7624\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.5380 - acc: 0.7456 - val_loss: 0.5140 - val_acc: 0.7624\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.5369 - acc: 0.7467 - val_loss: 0.5162 - val_acc: 0.7525\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.5358 - acc: 0.7467 - val_loss: 0.5152 - val_acc: 0.7525\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.5349 - acc: 0.7500 - val_loss: 0.5153 - val_acc: 0.7525\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.5342 - acc: 0.7478 - val_loss: 0.5163 - val_acc: 0.7525\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.5332 - acc: 0.7522 - val_loss: 0.5168 - val_acc: 0.7525\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.5328 - acc: 0.7511 - val_loss: 0.5153 - val_acc: 0.7525\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.5323 - acc: 0.7511 - val_loss: 0.5136 - val_acc: 0.7525\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.5321 - acc: 0.7533 - val_loss: 0.5148 - val_acc: 0.7525\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.5314 - acc: 0.7522 - val_loss: 0.5152 - val_acc: 0.7525\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.5306 - acc: 0.7522 - val_loss: 0.5140 - val_acc: 0.7525\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.5299 - acc: 0.7533 - val_loss: 0.5133 - val_acc: 0.7525\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.5288 - acc: 0.7556 - val_loss: 0.5130 - val_acc: 0.7525\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.5281 - acc: 0.7567 - val_loss: 0.5135 - val_acc: 0.7525\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.5277 - acc: 0.7578 - val_loss: 0.5155 - val_acc: 0.7525\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.5274 - acc: 0.7578 - val_loss: 0.5151 - val_acc: 0.7525\n",
      "Epoch 57/100\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.5261 - acc: 0.7567 - val_loss: 0.5143 - val_acc: 0.7525\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.5258 - acc: 0.7578 - val_loss: 0.5129 - val_acc: 0.7525\n",
      "Epoch 59/100\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.5253 - acc: 0.7578 - val_loss: 0.5137 - val_acc: 0.7525\n",
      "Epoch 60/100\n",
      "36/36 [==============================] - 3s 83ms/step - loss: 0.5248 - acc: 0.7556 - val_loss: 0.5137 - val_acc: 0.7525\n",
      "Epoch 61/100\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.5245 - acc: 0.7578 - val_loss: 0.5118 - val_acc: 0.7525\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 3s 86ms/step - loss: 0.5231 - acc: 0.7589 - val_loss: 0.5111 - val_acc: 0.7525\n",
      "Epoch 63/100\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.5232 - acc: 0.7611 - val_loss: 0.5121 - val_acc: 0.7525\n",
      "Epoch 64/100\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.5224 - acc: 0.7600 - val_loss: 0.5126 - val_acc: 0.7525\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.5221 - acc: 0.7589 - val_loss: 0.5118 - val_acc: 0.7525\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.5216 - acc: 0.7589 - val_loss: 0.5129 - val_acc: 0.7525\n",
      "Epoch 67/100\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.5212 - acc: 0.7578 - val_loss: 0.5129 - val_acc: 0.7525\n",
      "Epoch 68/100\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.5209 - acc: 0.7578 - val_loss: 0.5145 - val_acc: 0.7525\n",
      "Epoch 69/100\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.5205 - acc: 0.7567 - val_loss: 0.5143 - val_acc: 0.7525\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.5203 - acc: 0.7556 - val_loss: 0.5163 - val_acc: 0.7525\n",
      "Epoch 71/100\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.5196 - acc: 0.7544 - val_loss: 0.5164 - val_acc: 0.7525\n",
      "Epoch 72/100\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.5190 - acc: 0.7567 - val_loss: 0.5171 - val_acc: 0.7426\n",
      "Epoch 73/100\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.5185 - acc: 0.7578 - val_loss: 0.5190 - val_acc: 0.7426\n",
      "Epoch 74/100\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.5185 - acc: 0.7556 - val_loss: 0.5169 - val_acc: 0.7525\n",
      "Epoch 75/100\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.5181 - acc: 0.7578 - val_loss: 0.5168 - val_acc: 0.7426\n",
      "Epoch 76/100\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.5179 - acc: 0.7589 - val_loss: 0.5176 - val_acc: 0.7426\n",
      "Epoch 77/100\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.5176 - acc: 0.7578 - val_loss: 0.5163 - val_acc: 0.7426\n",
      "Epoch 78/100\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.5171 - acc: 0.7600 - val_loss: 0.5177 - val_acc: 0.7426\n",
      "Epoch 79/100\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.5166 - acc: 0.7611 - val_loss: 0.5175 - val_acc: 0.7426\n",
      "Epoch 80/100\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.5161 - acc: 0.7611 - val_loss: 0.5181 - val_acc: 0.7426\n",
      "Epoch 81/100\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.5155 - acc: 0.7622 - val_loss: 0.5176 - val_acc: 0.7327\n",
      "Epoch 82/100\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.5156 - acc: 0.7611 - val_loss: 0.5166 - val_acc: 0.7327\n",
      "Epoch 83/100\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.5148 - acc: 0.7589 - val_loss: 0.5173 - val_acc: 0.7426\n",
      "Epoch 84/100\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.5138 - acc: 0.7600 - val_loss: 0.5164 - val_acc: 0.7327\n",
      "Epoch 85/100\n",
      "36/36 [==============================] - 3s 78ms/step - loss: 0.5138 - acc: 0.7589 - val_loss: 0.5160 - val_acc: 0.7327\n",
      "Epoch 86/100\n",
      "36/36 [==============================] - 3s 71ms/step - loss: 0.5131 - acc: 0.7622 - val_loss: 0.5147 - val_acc: 0.7327\n",
      "Epoch 87/100\n",
      "36/36 [==============================] - 2s 70ms/step - loss: 0.5125 - acc: 0.7622 - val_loss: 0.5132 - val_acc: 0.7327\n",
      "Epoch 88/100\n",
      "36/36 [==============================] - 3s 71ms/step - loss: 0.5117 - acc: 0.7622 - val_loss: 0.5115 - val_acc: 0.7327\n",
      "Epoch 89/100\n",
      "36/36 [==============================] - 3s 71ms/step - loss: 0.5112 - acc: 0.7622 - val_loss: 0.5115 - val_acc: 0.7327\n",
      "Epoch 90/100\n",
      "36/36 [==============================] - 2s 69ms/step - loss: 0.5103 - acc: 0.7600 - val_loss: 0.5113 - val_acc: 0.7327\n",
      "Epoch 91/100\n",
      "36/36 [==============================] - 3s 75ms/step - loss: 0.5102 - acc: 0.7622 - val_loss: 0.5115 - val_acc: 0.7228\n",
      "Epoch 92/100\n",
      "36/36 [==============================] - 3s 78ms/step - loss: 0.5097 - acc: 0.7611 - val_loss: 0.5122 - val_acc: 0.7228\n",
      "Epoch 93/100\n",
      "36/36 [==============================] - 3s 71ms/step - loss: 0.5092 - acc: 0.7622 - val_loss: 0.5117 - val_acc: 0.7228\n",
      "Epoch 94/100\n",
      "36/36 [==============================] - 3s 74ms/step - loss: 0.5089 - acc: 0.7611 - val_loss: 0.5126 - val_acc: 0.7228\n",
      "Epoch 95/100\n",
      "36/36 [==============================] - 3s 72ms/step - loss: 0.5079 - acc: 0.7600 - val_loss: 0.5121 - val_acc: 0.7228\n",
      "Epoch 96/100\n",
      "36/36 [==============================] - 3s 76ms/step - loss: 0.5078 - acc: 0.7622 - val_loss: 0.5110 - val_acc: 0.7228\n",
      "Epoch 97/100\n",
      "36/36 [==============================] - 3s 76ms/step - loss: 0.5070 - acc: 0.7633 - val_loss: 0.5093 - val_acc: 0.7327\n",
      "Epoch 98/100\n",
      "36/36 [==============================] - 3s 80ms/step - loss: 0.5071 - acc: 0.7633 - val_loss: 0.5091 - val_acc: 0.7327\n",
      "Epoch 99/100\n",
      "36/36 [==============================] - 3s 79ms/step - loss: 0.5066 - acc: 0.7622 - val_loss: 0.5076 - val_acc: 0.7327\n",
      "Epoch 100/100\n",
      "36/36 [==============================] - 3s 78ms/step - loss: 0.5065 - acc: 0.7611 - val_loss: 0.5079 - val_acc: 0.7327\n"
     ]
    }
   ],
   "source": [
    "# instantiate DGCNN object\n",
    "dgcnn = DGCNN()\n",
    "# create the data generators used in model training and specify a training batch size of 25\n",
    "dgcnn.get_training_generators(train_graphs, train_index, train_labels, valid_index, valid_labels, 25)\n",
    "# create the DGCNN model, specifying all layer parameters\n",
    "dgcnn.create_DGCNN(layer_sizes = [32, 32, 32, 1], activations = ['tanh', 'tanh', 'tanh', 'tanh'], k = 35, \n",
    "                   num_kernels = [16, 32], kernel_sizes = [sum([32, 32, 32, 1]), 4], strides = [sum([32, 32, 32, 1]), 1],\n",
    "                   pool_size = 2, num_neurons = [32, 32], fc_activations = ['relu', 'relu', 'sigmoid'])\n",
    "# compile and train the DGCNN\n",
    "dgcnn.configure_train_DGCNN(learning_rate = 0.0001, loss_function = 'binary_crossentropy', epochs = 100)\n",
    "# create the data generator used in testing\n",
    "dgcnn.get_testing_generator(test_graphs, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43547219",
   "metadata": {},
   "source": [
    "We can view the model's predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bca4a325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>label</th>\n",
       "      <th>assessment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.122540</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.111393</td>\n",
       "      <td>1</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.403089</td>\n",
       "      <td>1</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.429360</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.105703</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.829533</td>\n",
       "      <td>1</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.193982</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.206989</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.846747</td>\n",
       "      <td>1</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.699649</td>\n",
       "      <td>1</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.075326</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.590481</td>\n",
       "      <td>1</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.097921</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.219774</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.082815</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.149859</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.233239</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.551149</td>\n",
       "      <td>1</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.116719</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.623587</td>\n",
       "      <td>1</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.085451</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    prediction  label assessment\n",
       "0     0.122540      0         TN\n",
       "1     0.111393      1         FN\n",
       "2     0.403089      1         FN\n",
       "3     0.429360      0         TN\n",
       "4     0.105703      0         TN\n",
       "5     0.829533      1         TP\n",
       "6     0.193982      0         TN\n",
       "7     0.206989      0         TN\n",
       "8     0.846747      1         TP\n",
       "9     0.699649      1         TP\n",
       "10    0.075326      0         TN\n",
       "11    0.590481      1         TP\n",
       "12    0.097921      0         TN\n",
       "13    0.219774      0         TN\n",
       "14    0.082815      0         TN\n",
       "15    0.149859      0         TN\n",
       "16    0.233239      0         TN\n",
       "17    0.551149      1         TP\n",
       "18    0.116719      0         TN\n",
       "19    0.623587      1         TP\n",
       "20    0.085451      0         TN"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgcnn.get_test_results()\n",
    "dgcnn.results_df[0:21]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827c68b0",
   "metadata": {},
   "source": [
    "Now let's view the numpy array of predicted classes. Verify with the 'prediction' column of the above dataframe. These predicted labels are required to generate the confusion matrix and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cbe29793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 1 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 1 1 1 0 0 1 0 1\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "dgcnn.evaluate_results()\n",
    "print(dgcnn.predicted_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05068f7",
   "metadata": {},
   "source": [
    "Precision is defined as \n",
    "$$P = \\frac{|TP|}{|TP| + |FP|}$$\n",
    "and recall as\n",
    "$$R = \\frac{|TP|}{|TP| + |FN|}$$\n",
    "where $|TP|$ is the number of true-positives, $|FP|$ is the number of false-positives, and $|FN|$ is the number of false-negatives. Precision essentially tells us the proportion of positive predictions that are actually correct, whereas the recall gives us the proportion of positive samples that are correctly predicted. A good classifier therefore, will have precision and recall close to one.\n",
    "\n",
    "Let's view some of the predictions made by the DGCNN model. Note that the above equations are defined for the positive class only, but we can in fact calculate the precision and recall for the negative class by switching the labels around, i.e., switching true-negatives for true-positives, and false-positives for false-negatives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41b4ef12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54 11]\n",
      " [15 32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.83      0.81        65\n",
      "           1       0.74      0.68      0.71        47\n",
      "\n",
      "    accuracy                           0.77       112\n",
      "   macro avg       0.76      0.76      0.76       112\n",
      "weighted avg       0.77      0.77      0.77       112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dgcnn.confusion_matrix)\n",
    "print(dgcnn.classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f42f32",
   "metadata": {},
   "source": [
    "We can see that performance on the positive class is worse than on the negative class. This is likely due to the class imabalance that exists between the two labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3295d397",
   "metadata": {},
   "source": [
    "Let's finish off by visualising the training history of the DGCNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "33599e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dgcnn.training_history()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
